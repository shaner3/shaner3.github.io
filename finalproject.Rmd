---
output:
  html_document: default
  pdf_document: default
---

A Data Analysis Tutorial: Airbnb

Motivaion: Airbnb is a temporary housing service that has taken off in recent years
in competition with the hotel and rental housing industry. Importantly, it
drastically reduces costs for guests. However, Airbnb is still largely unregulated (a point we will demonstrate further below). In large American cities like Chicago, the landlord is also usually legally obligated to disclose certain unsightly aspects of the property, up to and including safety hazards and history of building code violations. Tenants are very insulated from landlords by the law. Similarly, there are regulations set in place on hotels, as well as a substantial body of customer reviews for prospective guests to work with. Both of these temporary housing options come at a much higher price than Airbnb does, typically.

Thus, the question we aim to answer through our data analysis is a very broad one. If Airbnb is a very cheap living option but also relatively unregulated, how do I, as a prospective guest, choose the correct place to stay in, or help reduce the risks, if any, associated with using Airbnb in order to visit Chicago on the cheap?

Challenges with the data analysis: Airbnb hosts who live in the properties they list on Airbnb may only have guests in them every so often. This reduces the number of reviews that are published about such properties vastly, preventing prospective guests from feeling completely safe in their booking unless the host has been around for while. As a result, we will limit our review score analysis to listings that have 5 or more reviews at times below. On the other hand, Airbnb hosts that do not live in the properties they list (or list them out a lot) are more likely to be in violation of city rental housing laws in some form or fashion. There are risks associated with the selection of either type of host. There are two things that help remedy these issues. The first is that Airbnb will automatically write poor reviews for hosts that have frequent disputes with guests, provided the disputes are taken to Airbnb. That is, it will be harder to steer clear of a slightly creepy host that has not yet been reported to Airbnb, but we should at least be able to steer clear of the hosts that pose the largest risks to the guest, even if prior guests did not submit reviews afterwards.

```{r}
library(tidyverse)
library(stringr)

whole_listings_tab <- read_csv("listings.csv")
part_listings_tab <- whole_listings_tab %>% 
  select(id, host_id, host_since, host_about, host_response_rate,
    host_is_superhost, host_listings_count, host_identity_verified, property_type,
    price, minimum_nights, maximum_nights, availability_30, availability_60,
    availability_90, availability_365, number_of_reviews, review_scores_rating,
    review_scores_accuracy, review_scores_cleanliness, review_scores_checkin,
    review_scores_communication, review_scores_value, reviews_per_month, license,
    room_type, bed_type, longitude, latitude, zipcode, neighbourhood_cleansed,
    bed_type)
part_listings_tab

whole_listings1_tab <- read_csv("listings-1.csv")
part_listings1_tab <- whole_listings1_tab %>% 
  select(id, host_id, price, number_of_reviews, reviews_per_month,
    calculated_host_listings_count)
part_listings1_tab

```

Preprocessing and Curation: host_since, host_about, license, host_is_superhost, host_identity_verified, price

We only care about the length of time someone has been a host to a certain point in the data analysis. An interesting comparison could be hosts of less than a year, more than one year but less than two, more than two years but less than three, and more than three years. Similarly, we don't necessarily care about what the host's about section says or what their particular license is. We only care that they have one at all. Thus, we will replace these columns by something more useful to our analysis. In general, we will also clean up columns that contain true and false values, but are currently encoded with characters (is_superhost and is_ideneity_verified) and columns that represent numeric values, but are encoded as characters (price).

```{r}

analysis_tab <- part_listings_tab %>%
  mutate(response_rate = as.double(gsub("%", "", host_response_rate))) %>%
  mutate(cost = as.double(gsub(",", "", substr(price, 2,9)))) %>%
  mutate(is_superhost = ifelse(host_is_superhost == "t", TRUE, FALSE)) %>%
  mutate(identity_verified = ifelse(host_identity_verified == "t", TRUE, FALSE)) %>%
  mutate(has_license = ifelse(str_detect(license, 
    "[0-9][0-9][0-9][0-9][0-9][0-9][0-9]"), TRUE, FALSE)) %>%
  mutate(has_about = ifelse(is.na(host_about), FALSE, TRUE)) %>%
  mutate(years_as_host = as.numeric(difftime(as.Date("2017-05-17"),
    as.Date(host_since), unit="weeks"))/52.25) %>%
  select(id, host_id, response_rate, is_superhost, host_listings_count,
    identity_verified, property_type, cost, minimum_nights, maximum_nights,
    availability_30, availability_60, availability_90, availability_365,
    number_of_reviews, review_scores_rating, review_scores_accuracy,
    review_scores_cleanliness, review_scores_checkin, review_scores_communication,
    review_scores_value, reviews_per_month, has_license, has_about, years_as_host,
    room_type, bed_type, longitude, latitude, zipcode, neighbourhood_cleansed,
    bed_type)
analysis_tab
```


Point 1: Airbnb is highly unregulated.

This particular point provides almost the entire motiviation behind our analysis. Let's see if this is the case.

```{r}

ggplot(data=analysis_tab, aes(x=factor(has_license))) +
  geom_bar(stat="count") +
  labs(x = "Has a license")


```

As you can see, very, very few hosts in the Chicago area on Airbnb have gotten a guest house or vacation house license for their property, so there is relatively little bureaucratic vetting done with Airbnb properties currently (at least in Chicago). Thus, our analysis is indeed founded on a solid principle: It would be prudent of the prospective Airbnb user to be mindful of what host and property they pick, as very few of them have been inspected and/or vetted by the city. Without further ado, let's delve into the reviews. 

Point 2: Airbnb has inflated review scores.

```{r}

ggplot(data=analysis_tab, aes(x=review_scores_rating)) +
  geom_density() + 
  labs(x = "Review scores")

```

Numerically speaking, raw review scores mean very little when the overwhelming majority of listings have a review score lie at or above 80 out of 100. That is, if there are any red flags to ward off prospective Airbnb users from staying with a particular host that seems good enough, we will probably not be finding them through the raw review scores. This gives us the motivation to standardize the review score, allowing us to see more clearly which listings are reviewed better than others.

In addition to computing standardized review scores for all listings, we will also consider the mean standardized review scores of superhost listings and non-superhost listings to see if they are as good as Airbnb would have us believe (this is somewhat of a trivial point, but hey). We can make a box and whisker plot to visualize the differences in these distributions as well. We will also check up on the distribution of cost for superhost and non-superhost listings to see if our initial intuition that superhosts are the wrong idea for the most frugal among us is correct.

```{r}

all_reviews <- subset(analysis_tab, review_scores_rating != "NA" &
            number_of_reviews > 4, select=c(review_scores_rating, is_superhost,
            number_of_reviews, id, host_id, cost))
mean_all_reviews <- mean(all_reviews$review_scores_rating)
sd_all_reviews <- sd(all_reviews$review_scores_rating)

superhost_reviews <- subset(analysis_tab, review_scores_rating != "NA" &
            number_of_reviews > 4 & is_superhost, select=c(review_scores_rating,
            number_of_reviews, id, host_id))
mean_superhost_reviews <- mean(superhost_reviews$review_scores_rating)
sd_superhost_reviews <- sd(superhost_reviews$review_scores_rating)

ns_reviews <- subset(analysis_tab, review_scores_rating != "NA" & number_of_reviews
           > 4 & !is_superhost, select=c(review_scores_rating, number_of_reviews,
           id, host_id))
mean_ns_reviews <- mean(ns_reviews$review_scores_rating)
sd_ns_reviews <- sd(ns_reviews$review_scores_rating)

standardized_tab <- analysis_tab %>%
  mutate(z_review = (review_scores_rating - mean_all_reviews)/sd_all_reviews) %>%
  mutate(property_type_group = ifelse((property_type=="Apartment" & cost <= 100) |
        (property_type=="Bed & Breakfast" & cost <= 150) | (property_type=="Boat" &
        cost <= 150) | (property_type=="Boutique hotel" & cost <= 150) |
        (property_type=="Bungalow" & cost <= 110) | (property_type=="Dorm") |
        (property_type=="Condominium" & cost <= 140) | (property_type=="Guest
        Suite") | (property_type=="Guesthouse" & cost <= 120) |
        (property_type=="Hostel") | (property_type=="House" & cost <= 125) |
        (property_type=="In-law") | (property_type=="Loft" & cost <= 150) |
        (property_type=="Other" & cost <= 125) | (property_type=="Townhouse" & cost
        <= 130), "Single Room", ifelse((property_type=="Apartment" & cost <= 250) |
        (property_type=="Bed & Breakfast") | (property_type=="Boat" & cost <= 250)
        | (property_type=="Boutique hotel" & cost <= 250) |
        (property_type=="Bungalow") | (property_type=="Condominium" & cost <= 240)
        | (property_type=="Guesthouse" & cost <= 240) | (property_type=="House" &
        cost <= 250) | (property_type=="Loft" & cost <= 250) |
        (property_type=="Other" & cost <= 250) | (property_type=="Townhouse" & cost
        <= 250), "Fancy Room", ifelse(cost >= 240, "Entire property", "Other")))) %>% 
  select(z_review, id, host_id, response_rate, is_superhost,
        host_listings_count, identity_verified, property_type, cost,
        minimum_nights, maximum_nights, availability_30, availability_60,
        availability_90, availability_365, number_of_reviews,
        review_scores_accuracy, review_scores_cleanliness, review_scores_checkin,
        review_scores_communication, review_scores_value, reviews_per_month,
        has_license, has_about, years_as_host, property_type_group, room_type,
        bed_type, longitude, latitude, zipcode, neighbourhood_cleansed, bed_type)
  
standardized_tab

ggplot(analysis_tab, aes(x=is_superhost, y=review_scores_rating)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(60, 100)) + 
  labs(x = "Superhost status")

ggplot(analysis_tab, aes(x=is_superhost, y=cost)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(60, 100)) + 
  labs(x = "Superhost status", title="Cost by superhost status for all listings")

ggplot(all_reviews, aes(x=is_superhost, y=cost)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(60, 100)) + 
  labs(x = "Superhost status", title="Cost by superhost status for listings with >4 reviews")
  
```

We end up observing a mean of 95.10 for all reviews with a standard deviation of 4.73, along with a mean of 97.56 for superhost reviews with a standard deviation of 1.99, and finally a mean of 93.8 for non-superhost reviews with a standard deviation of 5.21. In general, this means we have much less variance with superhosts (higher chances of leaving a review about a great stay), and more variance with non-superhosts, alongside a lower expected rating for non-superhosts, all as expected. The boxplot also helps us visualize the differences discussed above.

And most interestingly we have the cost boxplot! It turned out we were actually wrong in our intuition. I had originally thought that superhosts would try to charge more for their Airbnb designation as a trustworthy and reliable host, but it turns out I was incorrect. This seems to suggest that achieving superhost status (around 10 visits in a year, 96 or higher average rating, and no cancellations barring major extenuating circumstances) only happens when you keep your price low, catering to the financial needs of those that use the service. This observation is maintained when we consider instead the cost of non-superhost listings with over 5 reviews. In fact, the mean price even shifts up ever so slightly! Superhosts are a damn good deal, apparently.

This is a good lead into our next issue: Superhost listings may be cheaper and have better ratings than non-superhost listings on average, but available more or less often than than their counterparts? If we were headed into Chicago for a major event, what are our options going to be, probabilistically speaking?

We now calculate the aggregate yearly availabilty (maximum number of nights bookable in a year if every timeslot in every listing was used), and check what portion of those nights are in superhost listings and non-superhost listings. This time, we will consider listings with at least 1 review and listings with at least 1 day available per year.


```{r}

availability <- subset(analysis_tab, number_of_reviews > 0 & availability_365 > 0,
            select= availability_365)
aggregate_availability <- sum(availability$availability_365)
mean_availability <- aggregate_availability/4237

superhost_availability <- subset(analysis_tab, number_of_reviews > 0 & 
                      availability_365 > 0 & is_superhost, select=
                      availability_365)
agg_superhost_availability <- sum(superhost_availability$availability_365)
mean_superhost_availability <- agg_superhost_availability/1248
portion_superhost <- agg_superhost_availability/aggregate_availability   

ns_availability <- subset(analysis_tab, number_of_reviews > 0 & availability_365 
                > 0 &!is_superhost, select= availability_365)
agg_ns_availability <- sum(ns_availability$availability_365)
mean_ns_availability <- agg_ns_availability/2989
portion_ns <- agg_ns_availability/aggregate_availability

aggregate_availability
mean_availability
portion_superhost
portion_ns

mean_superhost_availability
mean_ns_availability


```

The average yearly availabilty for superhost listings is actually very similar to that of non-superhost listings despite the fact that only 30% of the available timeslots in our dataset are listed by superhosts. This means that, independantly of what has already been booked, we expect there to be more non-superhosts to choose from when looking for an Airbnb listing at any given time. This is important to our motivation as being able to sift through these non-superhost listings to find the good ones will greatly widen our options beyond superhost listings, which may even be in higher demand (a point we examine in the next section).  

It also seems that 30% of the availabile timeslots in a year in our dataset are listed by superhosts. That's a little disconcerting if we had our heart set on getting a superhost listing because of their average higher reviews, lower costs, and trustworthiness. What if everyone wants a superhost right when we want to visit Chicago? This is another good question we can attempt to answer by using review counts as an indicator of demand. We now use similar code to measure what portion of reviews fall under superhost listings that are still available compared to what portion of reviews fall under non-superhost listings that are still available. 

```{r}

num_reviews <- subset(analysis_tab, number_of_reviews > 0 & availability_365 > 0,
            select = number_of_reviews)
aggregate_reviews <- sum(num_reviews$number_of_reviews)
average_reviews <- aggregate_reviews/4497

superhost_reviews <- subset(analysis_tab, number_of_reviews > 0 & availability_365
                  > 0 & is_superhost, select = number_of_reviews)
aggregate_superhost_reviews <- sum(superhost_reviews$number_of_reviews)
portion_superhost_reviews <- aggregate_superhost_reviews/aggregate_reviews
average_superhost_reviews <- aggregate_reviews/1248

ns_reviews <- subset(analysis_tab, number_of_reviews > 0 & availability_365 > 0 &
          !is_superhost, select = number_of_reviews)
aggregate_ns_reviews <- sum(ns_reviews$number_of_reviews)
portion_ns_reviews <- aggregate_ns_reviews/aggregate_reviews
average_ns_reviews <- aggregate_ns_reviews/2989

aggregate_reviews
average_reviews
portion_superhost_reviews
portion_ns_reviews

average_superhost_reviews
average_ns_reviews


```

I know we're a bit deep into the analysis at this point, but this is the truest proof of the reason behind the motivation possible. We have mentioned previously that superhost listings only comprise 30% of the available Airbnb listings in Chicago in a given year, based on our dataset. However, when we go and look at reviews, the superhost listings command an astonishing 42% of all reviews. That is, superhost listings may indeed have lower average costs and higher review scores, but they are also in demand more, if you are willing to assume every listing is equally likely to receive a review. 

Side note: Even if you are (wisely) unwilling to assume each listing is equally likely to receive a review, I think the idea that superhost listings are in higher demand than non-superhost listings given that superhost listings are avaialable less than their couterparts is a fair assumption nonetheless.

In any case, it would be extremely helpful to know, based on our data set, how we can pick through the non-superhost listings to find the good ones, especially when our non-superhost options do not have all that many (or any) reviews yet. Ideally, we want to know how to pick a non-superhost listing that will become a superhost listing, essentially. We could use a model and test it against results if we had cross-year data, but that will unfortunately have to come at a later date.

Without further ado, here is some statistically backed advice on how to choose an Airbnb host if they are not a superhost!

Tip #1: Older is not better.

```{r}


standardized_tab2 <- subset(standardized_tab, number_of_reviews != "NA" &
                  number_of_reviews > 0 & availability_365 != "NA" &
                  availability_365 > 0 & !is_superhost, select = c(z_review,
                  response_rate, number_of_reviews, identity_verified, has_about,
                  years_as_host, availability_365, availability_30,
                  availability_60, reviews_per_month, host_listings_count,
                  property_type_group, room_type, bed_type, longitude, latitude,
                  zipcode, neighbourhood_cleansed, cost))

standardized_tab3 <- standardized_tab2 %>% mutate(nearest_year =
                  ceiling(years_as_host)) %>% select(z_review, nearest_year)

ggplot(standardized_tab3, aes(x=factor(nearest_year), y=z_review)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(-2, 2)) + 
  labs(x = "Number of years as a host, rounded up", title="Distribution of Z-review scores based on years as host")

```

It is easy to fall into the mindset that the hosts that have been around for a while without getting tossed out probably aren't the ones that are going to kill you, but surprisingly we have found that the hosts still in their first few years with Airbnb who have not yet gotten promoted to superhosts actually get better reviews, if only marginally so, based on the dataset. 

However, we cannot, as of right now, say that all of these boxplots necessarily come from different distributions, and aren't just coincidental samples from the same distribution that happen to support our interpretation. We would need to amplify our sample size for each boxplot by including multiple cities in our dataset to run a confidence interval (see https://www.rdocumentation.org/packages/gmodels/versions/2.16.2/topics/ci) against the general pool of data in order to stand any chance of this observation being statistically significant, so this can at the very least serve as a promising issue to look into at a later date.

Tip #2: Identity verification does not impact review score

```{r}

ggplot(standardized_tab2, aes(x=factor(identity_verified), y=z_review)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(-6, 2)) + 
  labs(x = "Host has verified identity", title="Distribution of Z-review scores based on identity verification status")

```

Got your eyes on a place where the host has an unverified identity? You're probably fine. You might not have the same peace of mind as you would knowing that Airbnb has done some vetting of the host and location for you, but probabilistically speaking, it does not make that big of a difference on the rating you or anyone else gives at the end of it all.

Do note that this is yet another case where getting more data and doing a confidence interval would help make this observation more significant and applicable instead of general and particular to the dataset we happened to get.

Tip #3: Pick a host you feel like you connect with. Or not!

```{r}

ggplot(standardized_tab2, aes(x=factor(has_about), y=z_review)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(-2, 2)) + 
  labs(x = "Host has an about section", title="Distribution of Z-review scores based on about section status")

```

As someone who has looked through Airbnb, it doesn't feel great when the place you're thinking about staying in is listed by a host who doesn't tell you much about themselves. Fortunately, whether or not the host told the visitor much through their about section ahead of time seems to have had no negative impact on their rating of the experience. Whether this is true in general can be found, as we discussed previously, through the use of multiple datasets and a confidence interval.

Tip #4: Room type, bed type? What does it matter? I just need a place to sleep on the cheap!

```{r}

ggplot(standardized_tab2, aes(x=factor(bed_type), y=z_review)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(-2, 2)) + 
  labs(x = "Bed type", title="Distribution of Z-review scores based on bed type")

ggplot(standardized_tab2, aes(x=factor(room_type), y=z_review)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(-2, 2)) + 
  labs(x = "Room type", title="Distribution of Z-review scores based room type")

```

Everyone certainly has their preferences, but Airbnb seems to work best for those who prefer a solo-arrangement without too much preference in the way of sleeping amenities, provided they don't have to sleep on an airbed, based on this dataset. There certainly are other factors that could be at play here like cost and location, and the culture and tastes of those who visit Chicago using Airbnb (US citizens, I'd imagine). A deeper, more meaningful statement can be made with the use of some confidence interval testing!  

Tip #5: How cheap is too cheap?

```{r}

standardized_tab3 <- standardized_tab2 %>% mutate(price_bracket = ifelse(cost <
                  100, "0-100", ifelse(cost < 200, "100-200", ifelse(cost < 300,
                  "200-300", ifelse(cost < 400, "300-400", "400+"))))) %>%
                  select(price_bracket, cost, z_review)

ggplot(standardized_tab3, aes(x=factor(price_bracket), y=z_review)) + 
  geom_boxplot() +
  scale_y_continuous(limits = c(-2, 2)) + 
  labs(x = "Price Bracket", title="Distribution of Z-review scores price bracket")

```

For Chicago, there is no such thing as too cheap, honestly. The review distributions all look very similar.  

In summation, while it may not sound particularly flashy or safe, I'd imagine based off of the dataset that the people who stayed in a private room sleeping on a pullout couch at the residence of a first year Airbnb host with an unverified identity and just one review actually gave their host a great review, relatively speaking. This runs contrary to my own initial beliefs headed into this data analaysis piece, and I think it would be interesting to examine a single trend (bed type, room type, about section, verified identity, number of years as a host, etc) using multiple cities' datasets for further, more thoroughly backed statistical examination of what part of an Airbnb listing really matters when a guest does not have the option to stay with a superhost. I hope this piece has made the reader a little more trusting of the non-superhost Airbnb hosts!

Thanks for reading.